{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52fe0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a53c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412173e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_hdf(\"./data/in/title_script_summary_genres_score.h5\")\n",
    "data_df = data_df[pd.to_numeric(data_df['meta_score'], errors='coerce').notnull()]\n",
    "data_df['meta_score'] = pd.to_numeric(data_df['meta_score'])\n",
    "#data_df = data_df[data_df['title'] != 'American Outlaws']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6909124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_list(lst):\n",
    "    return [item for item in lst if item is not None and item != '' and re.search('[a-รถA-รถ]', item)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['split_script'] = data_df['script'].str.split(r'(?=\\n[^a-รถ]+(\\n|\\:\\s+))')\n",
    "data_df['split_script'] = data_df['split_script'].apply(clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d94ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = []\n",
    "for index, data in data_df.iterrows():\n",
    "    for line in data['split_script']:\n",
    "        if len(line.split()) > 512:\n",
    "            remove_list.append(data['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df[~data_df['title'].isin(remove_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee9557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased',\n",
    "                                        torch_dtype=torch.bfloat16,attn_implementation=\"flash_attention_2\").to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, model, tokenizer, device):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze()  # Taking the first token ([CLS]) embedding\n",
    "\n",
    "def encode_script(row, model, tokenizer, device):\n",
    "    vector_list = []\n",
    "    for line in row['split_script']:\n",
    "        vector = encode(line, model, tokenizer, device)\n",
    "        vector_list.append(vector.cpu().numpy())  # Move vectors to CPU to save GPU memory\n",
    "        torch.cuda.empty_cache()  # Frees up unutilized GPU memory\n",
    "    row['script_vectors'] = vector_list\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65351433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming data_df, model, and tokenizer are defined\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.half()  # Convert model to half precision\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorised_data_df = data_df.progress_apply(lambda x: encode_script(x, model, tokenizer, device), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae56a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorised_data_df.to_feather('vectorised_data_df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc97dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorised_data_df = pd.read_feather('vectorised_data_df.feather') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1f6f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorised_data_df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b614ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_series = vectorised_data_df[vectorised_data_df['title'] == 'Matrix, The'].squeeze(axis=0)\n",
    "#sum_vector = script_series['script_vectors'].sum()\n",
    "weights = [1]*len(script_series['script_vectors'])\n",
    "weights[1] = 0\n",
    "weights[2] = 0\n",
    "weights[3] = 0\n",
    "weighted_average_vector = np.average(script_series['script_vectors'], weights=weights)\n",
    "redundant_vector = script_series['script_vectors'][[1, 2, 3]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0176c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_series['split_script'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2916e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1b0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_sim_dict = {}\n",
    "for line, line_vector in list(zip(script_series['split_script'], script_series['script_vectors'])):\n",
    "    average_sim = cosine_similarity(line_vector.reshape(1, -1), weighted_average_vector.reshape(1, -1)).item()\n",
    "    redundant_sim = cosine_similarity(line_vector.reshape(1, -1), redundant_vector.reshape(1, -1)).item()\n",
    "    line_sim_dict[line] = average_sim/redundant_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c5b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(line_sim_dict.items(), key = lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10703f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorised_data_df['script_vectors']\n",
    "y = vectorised_data_df['meta_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a72d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15898cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure each inner array is a properly typed NumPy array (not of type object)\n",
    "standardized_X = [np.vstack(seq).astype(np.float32) for seq in X]\n",
    "\n",
    "# Convert each NumPy array to a PyTorch tensor\n",
    "tensor_X = [torch.tensor(seq) for seq in standardized_X]\n",
    "\n",
    "# Pad sequences\n",
    "padded_X = pad_sequence(tensor_X, batch_first=True, padding_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3816d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = padded_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff127cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def create_windows(data, window_size):\n",
    "    \"\"\"Generate windows for a single sequence.\"\"\"\n",
    "    n_windows = data.shape[0] - window_size + 1\n",
    "    return torch.stack([data[i:i+window_size] for i in range(n_windows)])\n",
    "\n",
    "def expand_labels(labels, window_size, sequence_length):\n",
    "    \"\"\"Expand labels to match the number of windows per sequence.\"\"\"\n",
    "    n_windows_per_sequence = sequence_length - window_size + 1\n",
    "    return labels.repeat_interleave(n_windows_per_sequence)\n",
    "\n",
    "def batched_window_creation_and_save(data, window_size, save_dir, batch_size=10):\n",
    "    \"\"\"Process data in batches, create windows, and save to disk in binary format.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Ensure the directory exists or create it if it doesn't\n",
    "    num_sequences = data.shape[0]\n",
    "    \n",
    "    for start_idx in tqdm(range(0, num_sequences, batch_size)):\n",
    "        end_idx = min(start_idx + batch_size, num_sequences)\n",
    "        batch_data = data[start_idx:end_idx]\n",
    "        all_windows = []\n",
    "\n",
    "        for seq in batch_data:\n",
    "            windows = create_windows(seq, window_size)  # Assuming you have a function create_windows\n",
    "            all_windows.append(windows)\n",
    "\n",
    "        if all_windows:\n",
    "            batch_windows_tensor = torch.cat(all_windows, dim=0)\n",
    "            # Save batch tensor to binary file\n",
    "            file_path = os.path.join(save_dir, f'batch_{start_idx//batch_size}.bin')\n",
    "            batch_windows_tensor.numpy().tofile(file_path)\n",
    "\n",
    "def batched_window_creation_and_save_compressed(data, window_size, save_dir, batch_size=10):\n",
    "    \"\"\"Process data in batches, create windows, and save to disk in HDF5 format with compression.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Ensure the directory exists or create it if it doesn't\n",
    "    num_sequences = data.shape[0]\n",
    "    \n",
    "    # Open an HDF5 file\n",
    "    hdf5_file = os.path.join(save_dir, 'windows.h5')\n",
    "    with h5py.File(hdf5_file, 'w') as file:\n",
    "        for start_idx in tqdm(range(0, num_sequences, batch_size)):\n",
    "            end_idx = min(start_idx + batch_size, num_sequences)\n",
    "            batch_data = data[start_idx:end_idx]\n",
    "            all_windows = []\n",
    "\n",
    "            for seq in batch_data:\n",
    "                windows = create_windows(seq, window_size)\n",
    "                all_windows.append(windows)\n",
    "\n",
    "            if all_windows:\n",
    "                batch_windows_tensor = torch.cat(all_windows, dim=0)\n",
    "                # Create a dataset in the HDF5 file with compression and chunking\n",
    "                dataset_name = f'batch_{start_idx//batch_size}'\n",
    "                chunks = (min(batch_windows_tensor.shape[0], 100), window_size, feature_dim)\n",
    "                file.create_dataset(dataset_name, \n",
    "                                    data=batch_windows_tensor.numpy(), \n",
    "                                    compression=\"lzf\",  # Change compression algorithm as needed\n",
    "                                    chunks=chunks)  # Specify chunk size\n",
    "\n",
    "def batched_window_creation_and_save_compressed_no_nulls(data, labels, window_size, save_dir, batch_size=10):\n",
    "    \"\"\"Process data in batches, create windows, and save to disk in HDF5 format with compression,\n",
    "       skipping windows that are all zeros and their corresponding labels.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Ensure the directory exists or create it if it doesn't\n",
    "    num_sequences = data.shape[0]\n",
    "    global_label_index = 0  # Initialize label index outside the batch loop\n",
    "    \n",
    "    hdf5_file = os.path.join(save_dir, 'windows.h5')\n",
    "    with h5py.File(hdf5_file, 'w') as file:\n",
    "        for start_idx in tqdm(range(0, num_sequences, batch_size)):\n",
    "            end_idx = min(start_idx + batch_size, num_sequences)\n",
    "            batch_data = data[start_idx:end_idx]\n",
    "            all_windows = []\n",
    "            valid_labels = []\n",
    "\n",
    "            for seq in batch_data:\n",
    "                windows = create_windows(seq, window_size)\n",
    "                for window in windows:\n",
    "                    if torch.any(window != 0):\n",
    "                        all_windows.append(window)\n",
    "                        if global_label_index < labels.size(0):  # Ensure we do not go out of bounds\n",
    "                            label = labels[global_label_index].to(torch.int64)\n",
    "                            valid_labels.append(label)\n",
    "                        global_label_index += 1  # Increment only for non-zero windows\n",
    "\n",
    "            if all_windows:\n",
    "                batch_windows_tensor = torch.stack(all_windows)\n",
    "                valid_labels_tensor = torch.tensor(valid_labels, dtype=torch.int64)\n",
    "                dataset_name = f'batch_{start_idx // batch_size}_data'\n",
    "                labelset_name = f'batch_{start_idx // batch_size}_labels'\n",
    "                chunks_data = (min(batch_windows_tensor.shape[0], 100), window_size, batch_data.shape[-1])\n",
    "                chunks_labels = (min(valid_labels_tensor.shape[0], 100),)\n",
    "                file.create_dataset(dataset_name,\n",
    "                                    data=batch_windows_tensor.numpy(),\n",
    "                                    compression=\"lzf\",\n",
    "                                    chunks=chunks_data)  # Specify chunk size for data\n",
    "                file.create_dataset(labelset_name,\n",
    "                                    data=valid_labels_tensor.numpy(),\n",
    "                                    compression=\"lzf\",\n",
    "                                    chunks=chunks_labels)  # Specify chunk size for labels\n",
    "\n",
    "    print(f\"Finished processing. Total non-zero windows processed: {len(all_windows)}. Total labels used: {global_label_index}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93163342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "num_sequences = 863\n",
    "sequence_length = 5288  # Length of each sequence\n",
    "feature_dim = 768 # Number of features per time step\n",
    "window_size = 60  # Define your window size\n",
    "save_dir = r'D:\\saved_windows_compressed_no_all_nulls'  # Define the directory to save the windows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b404655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels\n",
    "labels = torch.tensor(y.to_numpy())\n",
    "\n",
    "# Expand labels to match the number of windows per original sequence\n",
    "expanded_labels = expand_labels(labels, window_size, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7872e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f61e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create windows and save them to disk\n",
    "batched_window_creation_and_save_compressed_no_nulls(data, expanded_labels, window_size, save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c273d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from hdf5_dataset import HDF5Dataset\n",
    "\n",
    "dataset = HDF5Dataset(save_dir+'\\windows.h5', batch_ratio=0.25)\n",
    "try:\n",
    "    pickle.dumps(dataset)\n",
    "    print(\"Dataset is picklable!\")\n",
    "except pickle.PicklingError as e:\n",
    "    print(\"Dataset is not picklable:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d511c645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#targets = torch.tensor(y.to_numpy())  # Dummy target labels\n",
    "#targets = expanded_labels\n",
    "#print(padded_X_windowed.shape, targets.shape)\n",
    "# Create a TensorDataset\n",
    "#dataset = TensorDataset(padded_X_windowed, targets)\n",
    "\n",
    "\n",
    "\n",
    "# Total number of samples in your dataset\n",
    "n_samples = len(dataset)\n",
    "\n",
    "# Define split sizes\n",
    "train_size = int(n_samples * 0.7)\n",
    "val_size = int(n_samples * 0.2)\n",
    "test_size = n_samples - train_size - val_size  # Ensures all samples are used\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# You can now create DataLoader instances to easily batch your data during training/testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# Example: Access a batch from train_loader\n",
    "for data, labels in train_loader:\n",
    "    print(data.shape)\n",
    "    print('Data:', data)\n",
    "    print('Labels:', labels)\n",
    "    break  # Only show one batch for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiLayerLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, bidirectional=False):\n",
    "        super(MultiLayerLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, \n",
    "                            batch_first=True, bidirectional=bidirectional)\n",
    "        # Update the classifier to handle bidirectional output if needed\n",
    "        factor = 2 if bidirectional else 1\n",
    "        self.classifier = nn.Linear(hidden_dim * factor, 1)  # Output dimension is 1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Select the last time step from each sequence\n",
    "        if self.lstm.bidirectional:\n",
    "            # Concatenate the hidden states from the last and first time step for bidirectional\n",
    "            last_time_step = torch.cat((lstm_out[:, -1, :self.lstm.hidden_size], \n",
    "                                        lstm_out[:, 0, self.lstm.hidden_size:]), dim=-1)\n",
    "        else:\n",
    "            last_time_step = lstm_out[:, -1, :]\n",
    "        out = self.classifier(last_time_step)\n",
    "        # Scale the output to be within the range 0 to 100\n",
    "        #out = 100 * torch.sigmoid(out)  # Using sigmoid to normalize output between 0 and 1, then scale to 0-100\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3bc44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming input_size, hidden_size, and output_size are known\n",
    "input_size = 768  # This depends on your input feature size\n",
    "hidden_size = 500  # You can adjust this size\n",
    "hidden_layer_size = 3 \n",
    "\n",
    "model = MultiLayerLSTM(input_size, hidden_size, hidden_layer_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7597304",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5507c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a04e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        train_loss = 0.0\n",
    "        for data, labels in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            data, labels = data.to(device, non_blocking=True), labels.to(device, non_blocking=True).float().view(-1, 1)\n",
    "            outputs = model(data.squeeze(0))\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data, labels in tqdm(val_loader):\n",
    "                data, labels = data.to(device, non_blocking=True), labels.to(device, non_blocking=True).float().view(-1, 1)\n",
    "                outputs = model(data.squeeze(0))\n",
    "                val_loss += criterion(outputs, labels).item() * data.size(0)\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Step the scheduler with validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "# Make sure you create the model, criterion, optimizer, and scheduler before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92bfd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def evaluate_and_plot_model(model, test_loader):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = model.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    mse_loss = torch.nn.MSELoss()  # Initialize mean squared error loss\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in tqdm(test_loader):\n",
    "            data, labels = data.to(device, non_blocking=True), labels.to(device, non_blocking=True).float().view(-1, 1)\n",
    "            outputs = model(data.squeeze(0))\n",
    "            loss = mse_loss(outputs, labels)\n",
    "            total_loss += loss.item() * data.size(0)  # Multiply loss by batch size for accurate total\n",
    "            total_samples += data.size(0)\n",
    "\n",
    "            all_predictions.extend(outputs.view(-1).cpu().numpy())\n",
    "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
    "\n",
    "    average_loss = total_loss / total_samples\n",
    "    print(f'Average MSE Loss: {average_loss}')\n",
    "\n",
    "    # Plotting predictions vs actual labels\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(all_labels, all_predictions, alpha=0.5)\n",
    "    plt.title('Predictions vs Actual Labels')\n",
    "    plt.xlabel('Actual Labels')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.grid(True)\n",
    "    plt.plot([min(all_labels), max(all_labels)], [min(all_labels), max(all_labels)], 'k--')  # A reference line for perfect predictions\n",
    "    plt.show()\n",
    "\n",
    "    return average_loss, all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3bb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e686e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "average_loss = evaluate_and_plot_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "# Assume 'model' is your LSTM model and 'test_loader' is your DataLoader\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Get a batch of data; for visualization, one batch is enough\n",
    "for inputs, targets in train_loader:\n",
    "    inputs = inputs.to(device)  # Move inputs to the appropriate device\n",
    "    outputs = model(inputs)     # Forward pass\n",
    "    make_dot(outputs, params=dict(list(model.named_parameters()))).render(\"lstm_model\", format=\"png\")  # Visualize the model\n",
    "    break  # We only need one batch for visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
